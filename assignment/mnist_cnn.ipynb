{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "likely-kenya",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Trains a simple convnet on the MNIST dataset.\n",
    "\n",
    "Gets to 99.25% test accuracy after 12 epochs\n",
    "(there is still a lot of margin for parameter tuning).\n",
    "16 seconds per epoch on a GRID K520 GPU.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "oriented-dollar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "humanitarian-column",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compatible-monkey",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Complete the following function with cross entropy  loss\n",
    "#  sgd optimizer and also tell the model to evaluate the \n",
    "# accuracy\n",
    "#model.compile( ... )\n",
    "\n",
    "# Complete the code .\n",
    "#  Give the following inputs training and validation data, \n",
    "# number of epochs, batch size etc.\n",
    "# model.fit( ... )\n",
    "\n",
    "# Give the test data and find the results. \n",
    "#score = model.evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "passive-correction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "469/469 [==============================] - 13s 27ms/step - loss: 1.0075 - accuracy: 0.6847 - val_loss: 0.2981 - val_accuracy: 0.9134\n",
      "Epoch 2/12\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.4384 - accuracy: 0.8639 - val_loss: 0.2338 - val_accuracy: 0.9309\n",
      "Epoch 3/12\n",
      "469/469 [==============================] - 12s 26ms/step - loss: 0.3608 - accuracy: 0.8885 - val_loss: 0.1970 - val_accuracy: 0.9404\n",
      "Epoch 4/12\n",
      "469/469 [==============================] - 12s 26ms/step - loss: 0.3262 - accuracy: 0.9003 - val_loss: 0.1739 - val_accuracy: 0.9492\n",
      "Epoch 5/12\n",
      "469/469 [==============================] - 12s 26ms/step - loss: 0.3001 - accuracy: 0.9104 - val_loss: 0.1564 - val_accuracy: 0.9535\n",
      "Epoch 6/12\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.2772 - accuracy: 0.9167 - val_loss: 0.1528 - val_accuracy: 0.9524\n",
      "Epoch 7/12\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.2623 - accuracy: 0.9207 - val_loss: 0.1421 - val_accuracy: 0.9576\n",
      "Epoch 8/12\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.2520 - accuracy: 0.9235 - val_loss: 0.1312 - val_accuracy: 0.9613\n",
      "Epoch 9/12\n",
      "469/469 [==============================] - 12s 26ms/step - loss: 0.2382 - accuracy: 0.9289 - val_loss: 0.1271 - val_accuracy: 0.9628\n",
      "Epoch 10/12\n",
      "469/469 [==============================] - 12s 26ms/step - loss: 0.2278 - accuracy: 0.9320 - val_loss: 0.1228 - val_accuracy: 0.9629\n",
      "Epoch 11/12\n",
      "469/469 [==============================] - 12s 26ms/step - loss: 0.2184 - accuracy: 0.9342 - val_loss: 0.1152 - val_accuracy: 0.9657\n",
      "Epoch 12/12\n",
      "469/469 [==============================] - 12s 26ms/step - loss: 0.2076 - accuracy: 0.9380 - val_loss: 0.1123 - val_accuracy: 0.9640\n",
      "Test loss: 0.11228745430707932\n",
      "Test accuracy: 0.9639999866485596\n"
     ]
    }
   ],
   "source": [
    "sgd = SGD(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "middle-publication",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SPML Course Environment",
   "language": "python",
   "name": "spml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
